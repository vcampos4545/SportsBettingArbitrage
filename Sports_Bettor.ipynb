{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWnXvIaEybeu",
        "outputId": "4ec10dfa-aef5-443f-f24f-2c928d9c51d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successful Bootstrap!!!\n"
          ]
        }
      ],
      "source": [
        "#Remove Preexisting Files\n",
        "! rm -rf NBA-Machine-Learning-Sports-Betting\n",
        "! rm -rf *\n",
        "\n",
        "#Bootstrap Files\n",
        "! git clone https://github.com/kyleskom/NBA-Machine-Learning-Sports-Betting.git\n",
        "! mv -v ./NBA-Machine-Learning-Sports-Betting/* .\n",
        "! pip3 install -r requirements.txt\n",
        "\n",
        "#Clear Bootstrap Logs\n",
        "from IPython.display import clear_output \n",
        "clear_output()\n",
        "\n",
        "print(\"Successful Bootstrap!!!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCw0Ed3Uyxr7",
        "outputId": "ac6aecb1-f810-45d0-9b79-dcd332ff4905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python3: can't open file 'main.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "! python3 main.py -xgb -odds=fanduel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pSwcdROf6kvG"
      },
      "outputs": [],
      "source": [
        "##TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrfkqL4m_2kX",
        "outputId": "ece0a7ce-635f-4d7d-a205-8c2048370ada"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tweepy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/_p/4cdpxbv51plcbc0zl6hzbwk80000gn/T/ipykernel_32910/2653636879.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Add Twitter Sentiment Analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtextblob\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Authenticate with Twitter API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tweepy'"
          ]
        }
      ],
      "source": [
        "## Add Twitter Sentiment Analysis\n",
        "import tweepy\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Authenticate with Twitter API\n",
        "consumer_key = 'eq9QvcZRupgT1iBdqEbnu9Wea'\n",
        "consumer_secret = 'cvbu9YAI5TcGXkuVk6mNB54cNjlAo3Pbr3NcXGb109XFI2PcHX'\n",
        "access_token = '2479063608-4cx5s5H6wIRXZJBcM19MbGSBBLPUCuY8K54UYNv'\n",
        "access_token_secret = 'vpGBGHEzBrxNp1JKIeWSE9c1n5WMACamAeDVTcNFj8j8k'\n",
        "\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "# Search for tweets about the Warriors\n",
        "warriors_tweets = tweepy.Cursor(api.search, q='#Golden State Warriors').items(100)\n",
        "\n",
        "\n",
        "# Perform sentiment analysis on tweets\n",
        "positive_tweets = 0\n",
        "negative_tweets = 0\n",
        "neutral_tweets = 0\n",
        "\n",
        "for tweet in warriors_tweets:\n",
        "    analysis = TextBlob(tweet.text)\n",
        "    if analysis.sentiment.polarity > 0:\n",
        "        positive_tweets += 1\n",
        "    elif analysis.sentiment.polarity < 0:\n",
        "        negative_tweets += 1\n",
        "    else:\n",
        "        neutral_tweets += 1\n",
        "\n",
        "# Print results\n",
        "print(\"Positive tweets: \", positive_tweets)\n",
        "print(\"Negative tweets: \", negative_tweets)\n",
        "print(\"Neutral tweets: \", neutral_tweets)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVtf0ahbC6eo",
        "outputId": "f2a7840d-9f6c-48e0-b503-43fb0ae72223"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.26.1.tar.gz (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai) (3.8.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.59.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (2.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.26.1-py3-none-any.whl size=67316 sha256=729da3a688c20f73b776a229c5a6ad00c1ce250cf5a62a2ec509ed6c2b88f2b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/9c/55/95d3609ccfc463eeffb96d50c756f1f1899453b85e92021a0a\n",
            "Successfully built openai\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.26.1\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpzoF5AJCV6G",
        "outputId": "b891ea1e-bbb7-49f3-940e-80d550b3fcad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "The Fanduel odds data predicts that the Milwaukee Bucks will beat the Toronto Raptors, the Brooklyn Nets will beat the San Antonio Spurs, the Denver Nuggets will beat the Portland Trail Blazers, and the LA Clippers will beat the Philadelphia 76ers. The XGBoost Model Predictions agree with these predictions. The Milwaukee Bucks have an expected value of 38.61, while the Toronto Raptors have an expected value of -52.07. The San Antonio Spurs have an expected value of -49\n"
          ]
        }
      ],
      "source": [
        "## Add GPT Explanation\n",
        "\n",
        "\n",
        "# Import the OpenAI library\n",
        "import openai\n",
        "\n",
        "# Set the API key\n",
        "openai.api_key = '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'\n",
        "\n",
        "# Define the text to summarize\n",
        "text = \"------------------fanduel odds data------------------Toronto Raptors (106) @ Milwaukee Bucks (-124)Brooklyn Nets (-178) @ San Antonio Spurs (150)Portland Trail Blazers (194) @ Denver Nuggets (-235)Philadelphia 76ers (108) @ LA Clippers (-126)---------------XGBoost Model Predictions---------------Milwaukee Bucks (76.7%) vs Toronto Raptors: UNDER 222 (55.1%)San Antonio Spurs vs Brooklyn Nets (79.7%): UNDER 229.5 (56.8%)Denver Nuggets (77.7%) vs Portland Trail Blazers: UNDER 237 (79.1%)LA Clippers vs Philadelphia 76ers (58.7%): UNDER 223 (58.1%)--------------------Expected Value---------------------Milwaukee Bucks EV: 38.61Toronto Raptors EV: -52.07San Antonio Spurs EV: -49.2Brooklyn Nets EV: 24.45Denver Nuggets EV: 10.76Portland Trail Blazers EV: -34.44LA Clippers EV: -25.9Philadelphia 76ers EV: 22.07\"\n",
        "\n",
        "# Use the OpenAI API to summarize the text\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-002\",\n",
        "    prompt=(f\"summarize this text: {text}\"),\n",
        "    max_tokens=100\n",
        ")\n",
        "\n",
        "# Print the summary\n",
        "print(response[\"choices\"][0][\"text\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BI3cUhlEMki"
      },
      "outputs": [],
      "source": [
        "##1 Make Bet from API \n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
